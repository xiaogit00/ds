{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HcwePvKpw6-3"
   },
   "source": [
    "# Tutorial 2 (Week 2) - Descriptive Statistics and Hypothesis Testing\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "After completing this tutorial, you should be able to:\n",
    "\n",
    "+ Manipulate NumPy and Pandas data structures for statistics computation\n",
    "  + Group the dataset by variable values\n",
    "  + Filter the dataset for specific variable values\n",
    "+ Compute descriptive statistics for a dataset\n",
    "  + Compute statistics on arrays, Series, and DataFrame\n",
    "  + Apply statistical measures for decision making\n",
    "+ Fit a probability distribution to a dataset and estimate the parameters using SciPy\n",
    "+ Perform hypothesis testing using SciPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--SWM-0gj8MA"
   },
   "source": [
    "# Preface: Handling Data in Pandas and NumPy\n",
    "\n",
    "In Tutorial 1, we have used Pandas DataFrames and NumPy arrays in creating visualizations. We will now look at these data structures in more details so that we can perform more advanced operations with our data.\n",
    "\n",
    "_Tips:_ Throughout the tutorial, we will encounter various functions and properties in Pandas and NumPy. It is recommended that you make it a habit to look up the documentation (API reference and usage examples) of those you are not yet familiar with. This way, you form a better understanding of how you can use them in future, beyond the example problems in this tutorial.\n",
    "\n",
    "In Jupyter Notebook, the references are conveniently linked under the `Help` menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--SWM-0gj8MA"
   },
   "source": [
    "## NumPy Arrays\n",
    "\n",
    "NumPy is a fundamental package for scientific computing in Python. The main object in NumPy is `ndarray`, also known by the alias `array`. \n",
    "\n",
    "Numpy `array` is a table of elements (usually numbers), which is:\n",
    "- _Homogeneous_: elements are all of the same type;\n",
    "- _Multi-dimensional_: elements can be arranged into more than one __axes__;\n",
    "- _Indexed_: elements are addressable by a tuple of integers, one on each axis.\n",
    "\n",
    "The following image ([source](https://predictivehacks.com/tips-about-numpy-arrays/)) illustrates the array structure.\n",
    "\n",
    "<img src=\"https://predictivehacks.com/wp-content/uploads/2020/08/numpy_arrays-1024x572.png\" width=\"500\">\n",
    "\n",
    "Note that `numpy.array` is not the same as the Standard Python Library class `array.array`, which only handles one-dimensional arrays.\n",
    "\n",
    "Sample basic operations on numpy arrays are given below. Try running the codes and make sure you understand the output. You can go to [NumPy quickstart](https://numpy.org/doc/stable/user/quickstart.html) for more examples and practice.\n",
    "\n",
    "There are various ways to __create arrays__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  1],\n",
       "        [ 2,  3],\n",
       "        [ 4,  5]],\n",
       "\n",
       "       [[ 6,  7],\n",
       "        [ 8,  9],\n",
       "        [10, 11]],\n",
       "\n",
       "       [[12, 13],\n",
       "        [14, 15],\n",
       "        [16, 17]],\n",
       "\n",
       "       [[18, 19],\n",
       "        [20, 21],\n",
       "        [22, 23]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One of many ways to create an array\n",
    "a = np.arange(24).reshape(4, 3, 2)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take note of the array notation, and compare the above array display with the conceptual illustration to understand how it is represented in NumPy.\n",
    "\n",
    "Some __properties:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several methods to create arrays with __initialed content__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros( (3,5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25, 0.25, 0.25, 0.25, 0.25],\n",
       "       [0.25, 0.25, 0.25, 0.25, 0.25],\n",
       "       [0.25, 0.25, 0.25, 0.25, 0.25]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.full( (3,5), 0.25 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.rand( 3, 5 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Indexing__ operation retrieves the array element at `index`. For multi-dimensional arrays, `index` is a comma-separated tuple with one component for each axis. A negative component means counting from the last element on the axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "--SWM-0gj8MA"
   },
   "outputs": [],
   "source": [
    "a[3,2,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "--SWM-0gj8MA"
   },
   "outputs": [],
   "source": [
    "a[3,-2,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Slicing__ operation takes a range `start:stop` and returns a contiguous subset of array elements from `start` (_inclusive_) to `stop` (_exclusive_). Leaving `start` blank means slicing from the first element, while leaving `stop` blank means slicing until and including the last element.\n",
    "\n",
    "The slicer can take an optional third argument, making it `start:stop:step`, to set the interval at which elements are included in the slice. A negative step reverses the direction of the stepping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "--SWM-0gj8MA"
   },
   "outputs": [],
   "source": [
    "a[3,1:2,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "--SWM-0gj8MA"
   },
   "outputs": [],
   "source": [
    "a[3,1:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "--SWM-0gj8MA"
   },
   "outputs": [],
   "source": [
    "a[::2,:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conceptually, indexing returns an _element_ of the array, while slicing returns a _subset_ of the array. \n",
    "\n",
    "- A subset of an array is always another array. \n",
    "\n",
    "- An element of a 1D array is simply a value; an element of a 2D array is a 1D array, and so on. \n",
    "\n",
    "The indexing operation essentially narrows down to the element axis by axis, from axis 0 upwards. \n",
    "\n",
    "We can omit index components for higher axes (that is, stop narrowing down at one point) to retrieve all elements on remaining axes. This is equivalent to getting a complete slice of all remaining axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "--SWM-0gj8MA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22, 23])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[3,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "--SWM-0gj8MA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22, 23])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[3,2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "--SWM-0gj8MA"
   },
   "outputs": [],
   "source": [
    "a[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "--SWM-0gj8MA"
   },
   "outputs": [],
   "source": [
    "a[3,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Try this out:__ \n",
    "\n",
    "- Can you omit index components for lower axes (while specifying one or more higher axes index)? What elements do this retrieve? How is it different from slicing?\n",
    "\n",
    "- Can you omit index components for arbitrary axes (while specifying other axes index)? What elements do this retrieve? How is it different from slicing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Arithmetic operations__ on arrays are applied _element-wise_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a < 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--SWM-0gj8MA"
   },
   "source": [
    "## Pandas Series and DataFrame\n",
    "\n",
    "Pandas data table representation is __DataFrame__, a 2-dimensional data structure that can store data of different types in columns.\n",
    "\n",
    "<img src = \"https://pandas.pydata.org/pandas-docs/stable/_images/01_table_dataframe.svg\" width=\"360\">\n",
    "\n",
    "Each column in a DataFrame is a __Series__, a one-dimensional labeled array consisting of _index_ (the axis label) and data values. A Series object has a single data type, which can be any supported [`dtype`](https://pandas.pydata.org/docs/user_guide/basics.html#basics-dtypes) (integers, strings, Python objects, etc.).\n",
    "\n",
    "<img src = \"https://pandas.pydata.org/pandas-docs/stable/_images/01_table_series.svg\" width=\"120\">\n",
    "\n",
    "Sample basic operations on Series and DataFrame are given below. Try running the codes and make sure you understand the output. You can refer to [Pandas User Guide on data structures](https://pandas.pydata.org/docs/user_guide/dsintro.html) for more comprehensive guides.\n",
    "\n",
    "\n",
    "### Series Operations\n",
    "\n",
    "There are various ways to __create a Series__, such as from a NumPy array. We can specify the index or leave it as the default integer-based index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series( np.random.rand(5), index=[\"a\", \"b\", \"c\", \"d\", \"e\"] )\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--SWM-0gj8MA"
   },
   "source": [
    "The concepts of indexing, slicing, and element-wise arithmetic operations also apply to Series, with some differences in application compared to NumPy arrays. Various [indexing methods](https://pandas.pydata.org/docs/user_guide/indexing.html) are supported.\n",
    "\n",
    "__Indexing__ may use the index label or the integer position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Series.get()` method avoids throwing error for invalid labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.get('d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.get('f')  # What happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( s.get('f') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Slicing__ with a range is applied on the Series data as well as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[::2]  # with step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As Series has index labels, slicing can be done using labels as well, but the behaviour is different. Try this out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s['c':'e']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike with NumPy arrays, __arbitrary non-contiguous slicing__ is possible. We can specify a list of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note the inner [] for list notation\n",
    "s[['a','b','d']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also pass a boolean Series to pick elements corresponding to `True`-valued labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"Median:\", s.median() )\n",
    "\n",
    "# The > operation is applied element-wise, resulting in a Series of boolean values\n",
    "s[ s > s.median() ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame Operations\n",
    "\n",
    "Most of the time, the DataFrames we work with are the results of loading actual datasets. There are also other ways of __creating a DataFrame__, such as from a dict of Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "    \"one\": pd.Series( np.random.rand(5), index=list('abcde') ),\n",
    "    \"two\": pd.Series( ['Alice', 'Bob', 'Carol'], index=list('abc') )  # different length\n",
    "}\n",
    "# Observe how the different Series lengths are handled\n",
    "df = pd.DataFrame(d)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Select DataFrame columns__ by column name. The result is a Series, retaining the index. The column name is stored in the `name` attribute of the Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"one\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Select DataFrame rows__ by the row label using `df.loc`, or by the integer location using `df.iloc`. The result is also a Series, with the column names serving as index. The row label is stored in the `name` attribute of the Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.loc['c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can __add a new column__ to the DataFrame, e.g., from a Series. \n",
    "\n",
    "New columns are added at the end by default. `DataFrame.insert()` can be used to insert a column at a particular location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"flag\"] = pd.Series( np.ones(5), index=list('abcde') )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert( 2, \"three\", df[\"flag\"] - df[\"one\"] )\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also __set the value of an existing column__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"two\"] = ['Alice', 'Bob', 'Carol', 'Dale', 'Eva']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Delete a column__ with the Python `del` function. To remove the column but keep the data as a separate Series, __pop the column__ using `DataFrame.pop` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df[\"flag\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = df.pop( \"two\" )\n",
    "\n",
    "print( \"Names:\\n\", names )\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--SWM-0gj8MA"
   },
   "source": [
    "__`DataFrame.assign()`__ is a useful method to create new columns (potentially derived from existing columns) in a copy of the data, leaving the original DataFrame untouched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "--SWM-0gj8MA"
   },
   "outputs": [],
   "source": [
    "dfcopy = df.assign( four = df[\"one\"] * df[\"three\"] )\n",
    "dfcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can __rename columns__ using a mapping. The index (row labels) can similarly be renamed. Note that the rename operation returns a new DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcopy = dfcopy.rename( columns={\"three\" : \"factor\", \"four\" : \"product\"} )  # overwrite the existing DataFrame\n",
    "dfcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--SWM-0gj8MA"
   },
   "source": [
    "## Interoperability of Pandas and NumPy Data Structures\n",
    "\n",
    "Most NumPy functions can be called directly on Series and DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp( s )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.square( df )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have seen in Tutorial 1, however, some functions will require NumPy arrays. We can __convert a Series or a DataFrame into a NumPy array__ using `Series.to_numpy` or `DataFrame.to_numpy` functions respectively. With heterogenous data, the lowest common type will have to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--SWM-0gj8MA"
   },
   "source": [
    "Note that DataFrame is not intended to be a drop-in replacement for NumPy array as its indexing semantics and data model are quite different in places from an n-dimensional array.\n",
    "\n",
    "In situations when we can use either Pandas or NumPy functions, we may consider factors such as the speed or memory consumption, as summarized in this [Pandas vs Numpy comparison table](https://www.knowledgehut.com/blog/data-science/pandas-vs-numpy#pandas-vs-numpy-[comparison-table])."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to SciPy\n",
    "\n",
    "The SciPy package contains various toolboxes dedicated to common issues in scientific computing. \n",
    "\n",
    "Although there are basic statistical functions (mean, mode, etc.) that can be applied directly to [Series](https://pandas.pydata.org/docs/reference/series.html#computations-descriptive-stats), [DataFrames](https://pandas.pydata.org/docs/reference/frame.html#computations-descriptive-stats), and [NumPy arrays](https://numpy.org/devdocs/reference/routines.statistics.html), the real repository for statistical functions is in [`scipy.stats`](https://docs.scipy.org/doc/scipy/reference/stats.html).\n",
    "\n",
    "Let us work with a dataset next, to see how we can use the various packages to compute the statistics. We will also use some Matplotlib plotting functions along the way, so let's import that too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive Statistics\n",
    "\n",
    "For this tutorial, we will use the [food delivery time dataset](https://www.kaggle.com/datasets/bhanupratapbiswas/food-delivery-time-prediction-case-study).\n",
    "\n",
    "__EXERCISE:__ \n",
    "\n",
    "Load the dataset from the file `food_delivery_time.xlsx`. What Pandas function should you use to read the Excel format?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5iDCf5XVlKHt",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__EXERCISE:__ \n",
    "\n",
    "Rename the column names to make them easier to handle:\n",
    "```\n",
    "Delivery_person_*   --> Rider_*\n",
    "Delivery_location_* --> Customer_*\n",
    "Type_of_order       --> Order_Type\n",
    "Type_of_vehicle     --> Vehicle\n",
    "Time_taken(min)     --> Time\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon inspection, the values in the Order and Vehicle columns contain trailing whitespace, which may hinder our work later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery[\"Order_Type\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery[\"Vehicle\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__EXERCISE:__ \n",
    "\n",
    "Trim the whitespace from all values in these two columns and store them back in the same DataFrame. Look up the function from `Series.str` package that you can use for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery[\"Order_Type\"][0]  # check after replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery[\"Vehicle\"][0]  # check after replacement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__EXERCISE:__ \n",
    "\n",
    "What is the quickest way to find out (1) age range of all Riders, (2) mean Ratings across all orders, and (3) median of delivery time, directly on this DataFrame?\n",
    "\n",
    "_Hint:_ You have done a similar task in Tutorial 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DataFrame.describe` function is handy to quickly obtain basic statistics for all _numeric_ variables. These statistics are generated by excluding the missing values in the data, and the `count` value shows how many values in the column are used in the computation. As such, `count` is also a good indicator of the presence of missing values. \n",
    "\n",
    "Observe the output above and check whether this dataset have any missing values. (We will see how to deal with this situation when we learn Data Preprocessing later on in this course.)\n",
    "\n",
    "Of course, we can obtain the standalone statistical measures (count, mean, std, and so on) as well. You can refer to the documentations for the functions.\n",
    "\n",
    "__EXERCISE:__\n",
    "\n",
    "Using standalone functions, obtain the answer to the three questions above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Find the age range of all Riders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Find the mean Ratings across all orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Find the median of delivery time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Categorical variables__ are excluded from `DataFrame.describe`. As we would expect, measures like mean or median are not sensible for such variables. \n",
    "\n",
    "What statistics apply to categorical variables? These are count-related measures such as frequencies and proportion.\n",
    "\n",
    "__EXERCISE:__ \n",
    "\n",
    "Find out the most popular order type in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if your answer is correct by comparing it with the counts of all variables below. \n",
    "\n",
    "Suppose we want to optimize the delivery operations. Looking at all the counts, is the mode useful to make a decision on which order type to focus on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery[\"Order_Type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scipy.stats` has a `describe` function as well, which works on _a single numeric variable_ and gives a slightly different set of statistical measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.describe( delivery[\"Rider_Ratings\"] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping and Filtering\n",
    "\n",
    "Most of the time, statistics over the whole dataset do not give us a lot of meaningful information. For instance, not many useful conclusions can be drawn just by knowing the mean delivery time of all orders, given the variation in delivery distances and delivery vehicles. We would typically want to filter or group the dataset by values or conditions on the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oCJCeQIaq-hC"
   },
   "source": [
    "### Groupby\n",
    "\n",
    "We can use `DataFrame.groupby()` function to split the dataset based on values of a specific variable. This is typically done to obtain aggregate statistics for the resulting groups (as what we want to do here), or other useful functionalities in the _split-apply-combine_ framework for data analysis as explained in [this Pandas guide](https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html). \n",
    "\n",
    "The following image ([source](https://www.justintodata.com/pandas-groupby-with-python/)) illustrates the groupby mechanism.\n",
    "\n",
    "<img src=\"https://www.justintodata.com/wp-content/uploads/2020/04/image-4.png\">\n",
    "\n",
    "Note that no actual splitting is done when the GroupBy object is created. The function only verifies that we have passed a valid mapping. The splitting is only done when we explicitly use some method on this object or extract some of its attributes, such as `groups`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery.groupby( [\"Order_Type\", \"Vehicle\"] ).groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also view data in a specific group using `get_group`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery.groupby( [\"Order_Type\", \"Vehicle\"] ).get_group( (\"Drinks\", \"motorcycle\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oCJCeQIaq-hC"
   },
   "source": [
    "As mentioned, however, we typically want to apply some operation to the GroupBy object.\n",
    "\n",
    "__EXERCISE:__ \n",
    "\n",
    "Find the median delivery times for this dataset, grouped by vehicle types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering Rows\n",
    "\n",
    "Another useful operation is filtering rows, which is usually done as an indexing operation as we learned previously. We specify as index, a condition involving the values in certain column, e.g.:\n",
    "\n",
    "- `delivery[\"Vehicle\"] == \"scooter\"` or\n",
    "- `delivery[\"Rider_Age\"] > 25`\n",
    "\n",
    "These are arithmetic expressions which will be evaluated element-wise on the columns `delivery[\"Vehicle\"]` or `delivery[\"Rider_Age\"]`, resulting in a Series of boolean values: `True` for rows fulfilling the condition and `False` otherwise. Indexing `delivery` using this boolean Series will select only rows corresponding to `True` values.\n",
    "\n",
    "__EXERCISE:__ \n",
    "\n",
    "An order just came in and we are looking for riders on scooters to assign it to. How many riders can we choose from?\n",
    "\n",
    "_Hint:_ After filtering, what is the column we should be looking at? What Series function can you use to obtain the unique count?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__EXERCISE:__ \n",
    "\n",
    "How many of these scooter riders have achieved ratings higher than the median of this group?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__EXERCISE:__ \n",
    "\n",
    "What is the highest ratings that scooter riders have achieved? Show the IDs of all scooter riders who have achieved it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final exercise in this section, suppose we pick any scooter rider who have achieved ratings higher than the median to deliver all orders. Consider how we may satisfactorily estimate a delivery time to inform the customers.\n",
    "\n",
    "__EXERCISE:__\n",
    "\n",
    "First, let's try to obtain the summary statistics for the delivery time of this group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the mean and median (equal to the 50% percentile) values are close, we might think it would be a reasonable estimate to provide. But what will happen if we give this estimate to all customers? Clearly about half the customers would be upset because they would not receive their food within this time.\n",
    "\n",
    "So should we take the maximum delivery time, and provide a guaranteed delivery time of `max`? We may soon lose many customers as most people would not want to wait that long for their food.\n",
    "\n",
    "Instead, looking at the delivery time distribution, using a histogram, may guide our estimate better.\n",
    "\n",
    "__EXERCISE:__\n",
    "\n",
    "Use the `Series.hist` function to draw the histogram of delivery time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the histogram, we can verify the time duration in which most orders can be delivered. On the rare occasions that it takes longer, it could be because the restaurants are overcrowded, or the traffic jams are worse than usual.\n",
    "\n",
    "We could then determine a reasonable time range to provide to customers, and inform them that it might take longer in certain unexpected situations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GK98NTRUGR0s"
   },
   "source": [
    "# Probability Distributions with Scipy\n",
    "\n",
    "A _probability distribution_ describes phenomena that are influenced by random processes: naturally occurring random processes; or uncertainties caused by incomplete knowledge.\n",
    "\n",
    "The outcomes of a random process are called a _random variable, X_. The _distribution function_ maps probabilities to the occurrences of X.\n",
    "\n",
    "SciPy counts 104 continuous and 19 discrete distributions that can be instantiated in its `stats.rv_continuous` and `stats.rv_discrete` classes. Discrete distributions deal with countable outcomes, such as customers arriving at a counter. Continuous distributions compute the probability of occurrences between two outcomes or points on the x-axis, such as variations in height, temperature, or time.\n",
    "\n",
    "Distributions related to engineering and technology, which attempt to model, for instance, the lifetime or time to failure of equipment, as well as in biology and pharmaceutics, have blossomed in recent years, driven by the fast increasing availability of sensor data and other large sources of quantifiable information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GK98NTRUGR0s"
   },
   "source": [
    "## Normal Distribution\n",
    "\n",
    "The normal distribution, also called the Gaussian distribution, is a continuous probability distribution that is symmetric around its mean. It is arguably the most famous distribution due to its mathematical properties and its ability to describe many natural phenomena. It is typically great for mapping population data, for example, household income distribution. \n",
    "\n",
    "The normal distribution is characterized by two parameters: \n",
    "- the _mean (μ)_, which represents the central tendency of the distribution; and\n",
    "- the _standard deviation (σ)_, which measures the spread or dispersion of the data.\n",
    "By knowing these two parameters, we can fully describe a normal distribution.\n",
    "\n",
    "#### Distribution Fitting\n",
    "\n",
    "Fitting a normal distribution to a dataset allows us to estimate these parameters from the dataset. The `norm.fit` function in `scipy.stats` takes an array-like object as input and returns the maximum likelihood estimates (MLE) for the mean and standard deviation of the underlying distribution.\n",
    "\n",
    "Let us fit a normal distribution to our observed dataset of delivery time. To use the SciPy function, we need this data in NumPy array format.\n",
    "\n",
    "__EXERCISE:__\n",
    "\n",
    "Convert the delivery time data into a NumPy array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__EXERCISE:__\n",
    "\n",
    "Now use the `norm.fit` function to fit the normal distribution to the data. Note that it returns two values, corresponding to the two parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean is an estimator of the center of the distribution. The normal distribution distribution fit by SciPy should have the same center as the mean of the sample, as we have created a sample distribution.\n",
    "\n",
    "__EXERCISE:__\n",
    "\n",
    "Compute the mean of the sample array directly using NumPy, and verify that it has the same center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GbEUbei9GR0u"
   },
   "source": [
    "# Hypothesis Testing using SciPy\n",
    "\n",
    "A statistical test is a decision indicator. For instance, if we have two sets of observations, that we assume are generated from Gaussian processes, we can use a t-test to decide whether the means of two sets of observations are significantly different. \n",
    "\n",
    "Supppose we want to determine whether the average delivery time using motorcycles is significantly different from the mean delivery time of 26 minutes.\n",
    "\n",
    "__EXERCISE:__\n",
    "\n",
    "Obtain the NumPy array containing delivery time data for motorcycles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GbEUbei9GR0u"
   },
   "source": [
    "Consider the null hypothesis that the expected value (mean) of the motorcycles delivery time samples is equal to the given population mean. The `stats.ttest_1samp` function does two-sided test and returns the t-statistic and p-value.\n",
    "\n",
    "__EXERCISE:__\n",
    "\n",
    "Run the `ttest_1samp` function on the motorcycles delivery time data and given population mean. Let the significance value be 0.05. Can we reject the null hypothesis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-VGZ2kgjGR0u"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MzT_j4NEGR0u"
   },
   "source": [
    "Now let us investigate whether the mean delivery time using motorcycles is significantly different from the mean delivery time using bicycles.\n",
    "\n",
    "__EXERCISE:__\n",
    "\n",
    "Obtain the NumPy array containing delivery time data for bicycles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MzT_j4NEGR0u"
   },
   "source": [
    "We can use the `stats.ttest_ind` function to do a two-sided test for the null hypothesis that the two independent samples have identical average (expected) values.\n",
    "\n",
    "__EXERCISE:__\n",
    "\n",
    "Run the `ttest_ind` function on the motorcycles delivery time data and the bicycle delivery time data. Let the significance value be 0.05. Can we reject the null hypothesis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
